{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HHObSgfvWi-a",
    "outputId": "bc75b0b3-268f-43c0-ee5e-4cc90170bfd9"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolab\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m drive\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m      3\u001b[0m drive\u001b[38;5;241m.\u001b[39mmount(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/content/drive\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
     ]
    }
   ],
   "source": [
    "# from google.colab import drive\n",
    "# import os\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-YX83vLrKX1i",
    "outputId": "4862a96d-3374-4c1c-fb45-0ff51cae2799"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'energy-entropy-diffusion' already exists and is not an empty directory.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/lherron2/energy-entropy-diffusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DaYIe_9A7y4r",
    "outputId": "68557b39-51d1-4c7e-9c65-a0e99b919d1a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: not a git repository (or any of the parent directories): .git\n"
     ]
    }
   ],
   "source": [
    "!git pull https://github.com/lherron2/energy-entropy-diffusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XqgdwCNaxGPz",
    "outputId": "cd3d555c-88b9-44ce-8aac-b14a87f840c5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: memcnn in /usr/local/lib/python3.7/dist-packages (1.5.1)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from memcnn) (0.13.1+cu113)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from memcnn) (4.64.1)\n",
      "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from memcnn) (1.12.1+cu113)\n",
      "Requirement already satisfied: SimpleITK in /usr/local/lib/python3.7/dist-packages (from memcnn) (2.2.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from memcnn) (1.21.6)\n",
      "Requirement already satisfied: pathlib2 in /usr/local/lib/python3.7/dist-packages (from memcnn) (2.3.7.post1)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.0.0->memcnn) (4.1.1)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from pathlib2->memcnn) (1.15.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchvision->memcnn) (2.23.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->memcnn) (7.1.2)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->memcnn) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->memcnn) (2022.9.24)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->memcnn) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->memcnn) (1.24.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install memcnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1AuROqzDwtQ_",
    "outputId": "2c299116-d792-4e81-b915-2fa9dce5b53a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/energy-entropy-diffusion\n"
     ]
    }
   ],
   "source": [
    "%cd energy-entropy-diffusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "G5m7NASPw7Hl"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lukasherron/mambaforge/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9913344it [00:00, 27895048.61it/s]                                                                                                               \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST/raw/train-images-idx3-ubyte.gz to ./MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "29696it [00:00, 38407046.43it/s]                                                                                                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST/raw/train-labels-idx1-ubyte.gz to ./MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1649664it [00:00, 15056320.51it/s]                                                                                                               \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST/raw/t10k-images-idx3-ubyte.gz to ./MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5120it [00:00, 6220983.92it/s]                                                                                                                   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST/raw/t10k-labels-idx1-ubyte.gz to ./MNIST/raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "# import iunets\n",
    "from iunets import iUNet\n",
    "# from iunets.networks import SinusoidalPosEmb\n",
    "\n",
    "\n",
    "dataset = \"mnist\"\n",
    "\n",
    "if dataset== \"cifar\":\n",
    "  # Load CIFAR10 dataset\n",
    "  data = torchvision.datasets.CIFAR10(root='.',\n",
    "      download=True,\n",
    "      train=True, transform=\n",
    "          torchvision.transforms.Compose(\n",
    "              [torchvision.transforms.ToTensor()]\n",
    "      )\n",
    "  )\n",
    "  in_channels = 3\n",
    "\n",
    "if dataset == \"mnist\":\n",
    "  data = torchvision.datasets.MNIST(root='.',\n",
    "      download=True,\n",
    "      train=True, transform=\n",
    "          torchvision.transforms.Compose(\n",
    "              [torchvision.transforms.ToTensor()]\n",
    "      )\n",
    "  )\n",
    "  in_channels = 1\n",
    "\n",
    "data_loader = torch.utils.data.DataLoader(\n",
    "    data,\n",
    "    batch_size=128,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RBCIV1r3g2cX",
    "outputId": "2038594f-1169-41c4-bff6-b149cc5a496d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_channels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n8PI6jFGxEPM",
    "outputId": "0791317f-0362-43f6-bbef-35b883908e18"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "2.0\n",
      "2.0\n",
      "Could not exactly create an iUNet with channels=(3, 3, 8, 16) and resampling_stride=[(2, 2), (2, 2), (2, 2)]. Instead using closest achievable configuration: channels=(3, 4, 8, 16). Average relative error: 0.1111111111111111\n",
      "self.out_channels 1\n",
      "channel_multiplier 4\n",
      "num_F_in_channels: 2\n",
      "num_F_out_channels: 1\n",
      "num_F_in_channels: 2\n",
      "num_F_out_channels: 1\n",
      "num_F_in_channels: 1\n",
      "num_F_out_channels: 2\n",
      "num_F_in_channels: 1\n",
      "num_F_out_channels: 2\n",
      "self.out_channels 2\n",
      "channel_multiplier 4\n",
      "num_F_in_channels: 2\n",
      "num_F_out_channels: 2\n",
      "num_F_in_channels: 2\n",
      "num_F_out_channels: 2\n",
      "num_F_in_channels: 2\n",
      "num_F_out_channels: 2\n",
      "num_F_in_channels: 2\n",
      "num_F_out_channels: 2\n",
      "self.out_channels 4\n",
      "channel_multiplier 4\n",
      "num_F_in_channels: 4\n",
      "num_F_out_channels: 4\n",
      "num_F_in_channels: 4\n",
      "num_F_out_channels: 4\n",
      "num_F_in_channels: 4\n",
      "num_F_out_channels: 4\n",
      "num_F_in_channels: 4\n",
      "num_F_out_channels: 4\n",
      "num_F_in_channels: 8\n",
      "num_F_out_channels: 8\n",
      "num_F_in_channels: 8\n",
      "num_F_out_channels: 8\n",
      "num_F_in_channels: 8\n",
      "num_F_out_channels: 8\n",
      "num_F_in_channels: 8\n",
      "num_F_out_channels: 8\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m model \u001b[38;5;241m=\u001b[39m iUNet(\n\u001b[1;32m      2\u001b[0m     in_channels\u001b[38;5;241m=\u001b[39min_channels,\n\u001b[1;32m      3\u001b[0m     channels\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m8\u001b[39m,\u001b[38;5;241m16\u001b[39m),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      7\u001b[0m     disable_custom_gradient\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m      8\u001b[0m )\n\u001b[0;32m----> 9\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m     11\u001b[0m model\u001b[38;5;241m.\u001b[39mprint_layout()\n",
      "File \u001b[0;32m~/mambaforge/lib/python3.9/site-packages/torch/nn/modules/module.py:907\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    903\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    904\u001b[0m                     non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[1;32m    905\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, non_blocking)\n\u001b[0;32m--> 907\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/lib/python3.9/site-packages/torch/nn/modules/module.py:578\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    576\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_apply\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn):\n\u001b[1;32m    577\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 578\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    580\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    581\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    582\u001b[0m             \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    583\u001b[0m             \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    588\u001b[0m             \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    589\u001b[0m             \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/mambaforge/lib/python3.9/site-packages/torch/nn/modules/module.py:578\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    576\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_apply\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn):\n\u001b[1;32m    577\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 578\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    580\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    581\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    582\u001b[0m             \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    583\u001b[0m             \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    588\u001b[0m             \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    589\u001b[0m             \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "    \u001b[0;31m[... skipping similar frames: Module._apply at line 578 (4 times)]\u001b[0m\n",
      "File \u001b[0;32m~/mambaforge/lib/python3.9/site-packages/torch/nn/modules/module.py:578\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    576\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_apply\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn):\n\u001b[1;32m    577\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 578\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    580\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    581\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    582\u001b[0m             \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    583\u001b[0m             \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    588\u001b[0m             \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    589\u001b[0m             \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/mambaforge/lib/python3.9/site-packages/torch/nn/modules/module.py:601\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    597\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    598\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    599\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    600\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 601\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    602\u001b[0m should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    603\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m should_use_set_data:\n",
      "File \u001b[0;32m~/mambaforge/lib/python3.9/site-packages/torch/nn/modules/module.py:905\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    902\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m    903\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    904\u001b[0m                 non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[0;32m--> 905\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/lib/python3.9/site-packages/torch/cuda/__init__.py:210\u001b[0m, in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    207\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot re-initialize CUDA in forked subprocess. To use CUDA with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    208\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultiprocessing, you must use the \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspawn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m start method\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    209\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(torch\u001b[38;5;241m.\u001b[39m_C, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_cuda_getDeviceCount\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m--> 210\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTorch not compiled with CUDA enabled\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    211\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _cudart \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    212\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[1;32m    213\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlibcudart functions unavailable. It looks like you have a broken build?\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "\n",
    "model = iUNet(\n",
    "    in_channels=in_channels,\n",
    "    channels=(3,3,8,16),\n",
    "    dim=2,\n",
    "    architecture=(2,2,2,2),\n",
    "    # create_module_fn=\"create_conditional_module\",\n",
    "    disable_custom_gradient=True\n",
    ")\n",
    "model = model.to('cuda')\n",
    "model.train()\n",
    "model.print_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "jhwX5rfp4YGc"
   },
   "outputs": [],
   "source": [
    "def mse(outputs, targets):\n",
    "    (bs, _, dim, _) = targets.shape\n",
    "    loss = ((targets - outputs)**2).view(bs,-1).sum(1).mean()/dim**2\n",
    "    return loss\n",
    "\n",
    "def energy(outputs):\n",
    "    loss = (outputs**2).view(bs,-1).sum(1).mean()/dim**2\n",
    "    return loss\n",
    "\n",
    "def entropy(ldj):\n",
    "    return ldj.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "CvfQRf7K4hHX"
   },
   "outputs": [],
   "source": [
    "beta=1e-3\n",
    "\n",
    "batch_size = 128\n",
    "# image_size = 27\n",
    "# channels = 3\n",
    "num_diffusion_timesteps = 1000\n",
    "beta_start = 0.0001\n",
    "beta_end = 0.02\n",
    "device=\"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "18-HNkVGGboU"
   },
   "outputs": [],
   "source": [
    "def get_beta_schedule(beta_start, beta_end, num_diffusion_timesteps):\n",
    "    return np.linspace(beta_start, beta_end, num_diffusion_timesteps, dtype=np.float64)\n",
    "\n",
    "def compute_alpha(beta, t):\n",
    "    beta = torch.cat([torch.zeros(1).to(beta.device), beta], dim=0)\n",
    "    a = (1 - beta).cumprod(dim=0).index_select(0, t).view(-1, 1, 1, 1)\n",
    "    return a\n",
    "\n",
    "def mse(output, e):\n",
    "    (bs, _, dim, _) = output.shape\n",
    "    loss = (e - output).square().sum(dim=(1, 2, 3)).mean(dim=0)/dim**2\n",
    "    return loss\n",
    "\n",
    "def energy(output):\n",
    "  (bs, _, dim, _) = output.shape\n",
    "  loss = (output**2).sum(dim=(1,2,3)).mean()/dim**2\n",
    "  return loss\n",
    "\n",
    "def entropy(ldj):\n",
    "    return ldj.mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "wTE9a0ADGhi3"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [14]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m betas \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(\n\u001b[1;32m      2\u001b[0m     get_beta_schedule(beta_start, beta_end, num_diffusion_timesteps))\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m----> 4\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(\u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-4\u001b[39m, weight_decay\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m      5\u001b[0m         betas\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m0.9\u001b[39m, \u001b[38;5;241m0.999\u001b[39m), amsgrad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m      6\u001b[0m         eps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-9\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "betas = torch.from_numpy(\n",
    "    get_beta_schedule(beta_start, beta_end, num_diffusion_timesteps)).float().to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4, weight_decay=0,\n",
    "        betas=(0.9, 0.999), amsgrad=False,\n",
    "        eps=1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 394
    },
    "id": "68bI8suGGpkb",
    "outputId": "afee4a34-b8e4-4a67-be19-8264e2fe3dab"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [11]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m model_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m      3\u001b[0m entropy_arr, energy_arr, mse_arr, loss_arr \u001b[38;5;241m=\u001b[39m [], [], [], []\n\u001b[0;32m----> 4\u001b[0m \u001b[43mos\u001b[49m\u001b[38;5;241m.\u001b[39mmakedirs(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/content/drive/Shareddrives/final_project/models/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/metrics\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[1;32m      5\u001b[0m             exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m40\u001b[39m):\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;66;03m# for i, x0 in enumerate(train_loader):\u001b[39;00m\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, (x0, _) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(data_loader):\n",
      "\u001b[0;31mNameError\u001b[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "step = 0\n",
    "model_idx = 0\n",
    "entropy_arr, energy_arr, mse_arr, loss_arr = [], [], [], []\n",
    "os.makedirs(f\"/content/drive/Shareddrives/final_project/models/{dataset}/metrics\", \n",
    "            exist_ok=True)\n",
    "\n",
    "for epoch in range(0, 40):\n",
    "    # for i, x0 in enumerate(train_loader):\n",
    "    for i, (x0, _) in enumerate(data_loader):\n",
    "\n",
    "        n = x0.size(0)\n",
    "        x0 = x0.to(device)\n",
    "        e = torch.normal(0, 1, size=x0.size()).to(device)    \n",
    "        b = betas.to(device)\n",
    "        t = torch.randint(low=0, high=1000, size=(n,)).to(device)\n",
    "        a = compute_alpha(b, t).to(device)\n",
    "        x = x0 * a.sqrt() + e * (1-a).sqrt()\n",
    "        output, times, log_det_jac = model(x, t.float())\n",
    "        mse_loss = mse(output, e)\n",
    "        energy_loss = energy(output)\n",
    "        entropy_loss = - beta*entropy(log_det_jac)\n",
    "        loss = mse_loss + energy_loss + entropy_loss\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if i % 100 == 0:\n",
    "            print(loss.detach())\n",
    "            entropy_arr.append(entropy_loss.cpu().detach().numpy())\n",
    "            energy_arr.append(energy_loss.cpu().detach().numpy())\n",
    "            mse_arr.append(mse_loss.cpu().detach().numpy())\n",
    "            loss_arr.append(loss.cpu().detach().numpy())\n",
    "\n",
    "        if step % 10000 == 0:\n",
    "            torch.save(model, os.path.join(f\"/content/drive/Shareddrives/final_project/models/{dataset}\", \n",
    "                                    f\"cifar_model_{step}.pt\"))\n",
    "            np.savez(os.path.join(f\"/content/drive/Shareddrives/final_project/models/{dataset}/metrics\",\n",
    "                                 f\"metrics_model_{step}.npz\"), \n",
    "                     entropy=np.array(entropy_arr), energy=np.array(energy_arr), mse=np.array(mse_arr), \n",
    "                     loss=np.array(loss_arr))\n",
    "        step += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZXd0d5HQha-q",
    "outputId": "1e61a9a6-b6cc-49fa-bec9-0c34568b3374"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 1, 28, 28])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ij2vCrS2fG0v"
   },
   "outputs": [],
   "source": [
    "eta = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l9_dwHbVVs3I",
    "outputId": "48bce211-1121-4803-b7e5-214ade8de9f4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "999 998\n",
      "998 997\n",
      "997 996\n",
      "996 995\n",
      "995 994\n",
      "994 993\n",
      "993 992\n",
      "992 991\n",
      "991 990\n",
      "990 989\n",
      "989 988\n",
      "988 987\n",
      "987 986\n",
      "986 985\n",
      "985 984\n",
      "984 983\n",
      "983 982\n",
      "982 981\n",
      "981 980\n",
      "980 979\n",
      "979 978\n",
      "978 977\n",
      "977 976\n",
      "976 975\n",
      "975 974\n",
      "974 973\n",
      "973 972\n",
      "972 971\n",
      "971 970\n",
      "970 969\n",
      "969 968\n",
      "968 967\n",
      "967 966\n",
      "966 965\n",
      "965 964\n",
      "964 963\n",
      "963 962\n",
      "962 961\n",
      "961 960\n",
      "960 959\n",
      "959 958\n",
      "958 957\n",
      "957 956\n",
      "956 955\n",
      "955 954\n",
      "954 953\n",
      "953 952\n",
      "952 951\n",
      "951 950\n",
      "950 949\n",
      "949 948\n",
      "948 947\n",
      "947 946\n",
      "946 945\n",
      "945 944\n",
      "944 943\n",
      "943 942\n",
      "942 941\n",
      "941 940\n",
      "940 939\n",
      "939 938\n",
      "938 937\n",
      "937 936\n",
      "936 935\n",
      "935 934\n",
      "934 933\n",
      "933 932\n",
      "932 931\n",
      "931 930\n",
      "930 929\n",
      "929 928\n",
      "928 927\n",
      "927 926\n",
      "926 925\n",
      "925 924\n",
      "924 923\n",
      "923 922\n",
      "922 921\n",
      "921 920\n",
      "920 919\n",
      "919 918\n",
      "918 917\n",
      "917 916\n",
      "916 915\n",
      "915 914\n",
      "914 913\n",
      "913 912\n",
      "912 911\n",
      "911 910\n",
      "910 909\n",
      "909 908\n",
      "908 907\n",
      "907 906\n",
      "906 905\n",
      "905 904\n",
      "904 903\n",
      "903 902\n",
      "902 901\n",
      "901 900\n",
      "900 899\n",
      "899 898\n",
      "898 897\n",
      "897 896\n",
      "896 895\n",
      "895 894\n",
      "894 893\n",
      "893 892\n",
      "892 891\n",
      "891 890\n",
      "890 889\n",
      "889 888\n",
      "888 887\n",
      "887 886\n",
      "886 885\n",
      "885 884\n",
      "884 883\n",
      "883 882\n",
      "882 881\n",
      "881 880\n",
      "880 879\n",
      "879 878\n",
      "878 877\n",
      "877 876\n",
      "876 875\n",
      "875 874\n",
      "874 873\n",
      "873 872\n",
      "872 871\n",
      "871 870\n",
      "870 869\n",
      "869 868\n",
      "868 867\n",
      "867 866\n",
      "866 865\n",
      "865 864\n",
      "864 863\n",
      "863 862\n",
      "862 861\n",
      "861 860\n",
      "860 859\n",
      "859 858\n",
      "858 857\n",
      "857 856\n",
      "856 855\n",
      "855 854\n",
      "854 853\n",
      "853 852\n",
      "852 851\n",
      "851 850\n",
      "850 849\n",
      "849 848\n",
      "848 847\n",
      "847 846\n",
      "846 845\n",
      "845 844\n",
      "844 843\n",
      "843 842\n",
      "842 841\n",
      "841 840\n",
      "840 839\n",
      "839 838\n",
      "838 837\n",
      "837 836\n",
      "836 835\n",
      "835 834\n",
      "834 833\n",
      "833 832\n",
      "832 831\n",
      "831 830\n",
      "830 829\n",
      "829 828\n",
      "828 827\n",
      "827 826\n",
      "826 825\n",
      "825 824\n",
      "824 823\n",
      "823 822\n",
      "822 821\n",
      "821 820\n",
      "820 819\n",
      "819 818\n",
      "818 817\n",
      "817 816\n",
      "816 815\n",
      "815 814\n",
      "814 813\n",
      "813 812\n",
      "812 811\n",
      "811 810\n",
      "810 809\n",
      "809 808\n",
      "808 807\n",
      "807 806\n",
      "806 805\n",
      "805 804\n",
      "804 803\n",
      "803 802\n",
      "802 801\n",
      "801 800\n",
      "800 799\n",
      "799 798\n",
      "798 797\n",
      "797 796\n",
      "796 795\n",
      "795 794\n",
      "794 793\n",
      "793 792\n",
      "792 791\n",
      "791 790\n",
      "790 789\n",
      "789 788\n",
      "788 787\n",
      "787 786\n",
      "786 785\n",
      "785 784\n",
      "784 783\n",
      "783 782\n",
      "782 781\n",
      "781 780\n",
      "780 779\n",
      "779 778\n",
      "778 777\n",
      "777 776\n",
      "776 775\n",
      "775 774\n",
      "774 773\n",
      "773 772\n",
      "772 771\n",
      "771 770\n",
      "770 769\n",
      "769 768\n",
      "768 767\n",
      "767 766\n",
      "766 765\n",
      "765 764\n",
      "764 763\n",
      "763 762\n",
      "762 761\n",
      "761 760\n",
      "760 759\n",
      "759 758\n",
      "758 757\n",
      "757 756\n",
      "756 755\n",
      "755 754\n",
      "754 753\n",
      "753 752\n",
      "752 751\n",
      "751 750\n",
      "750 749\n",
      "749 748\n",
      "748 747\n",
      "747 746\n",
      "746 745\n",
      "745 744\n",
      "744 743\n",
      "743 742\n",
      "742 741\n",
      "741 740\n",
      "740 739\n",
      "739 738\n",
      "738 737\n",
      "737 736\n",
      "736 735\n",
      "735 734\n",
      "734 733\n",
      "733 732\n",
      "732 731\n",
      "731 730\n",
      "730 729\n",
      "729 728\n",
      "728 727\n",
      "727 726\n",
      "726 725\n",
      "725 724\n",
      "724 723\n",
      "723 722\n",
      "722 721\n",
      "721 720\n",
      "720 719\n",
      "719 718\n",
      "718 717\n",
      "717 716\n",
      "716 715\n",
      "715 714\n",
      "714 713\n",
      "713 712\n",
      "712 711\n",
      "711 710\n",
      "710 709\n",
      "709 708\n",
      "708 707\n",
      "707 706\n",
      "706 705\n",
      "705 704\n",
      "704 703\n",
      "703 702\n",
      "702 701\n",
      "701 700\n",
      "700 699\n",
      "699 698\n",
      "698 697\n",
      "697 696\n",
      "696 695\n",
      "695 694\n",
      "694 693\n",
      "693 692\n",
      "692 691\n",
      "691 690\n",
      "690 689\n",
      "689 688\n",
      "688 687\n",
      "687 686\n",
      "686 685\n",
      "685 684\n",
      "684 683\n",
      "683 682\n",
      "682 681\n",
      "681 680\n",
      "680 679\n",
      "679 678\n",
      "678 677\n",
      "677 676\n",
      "676 675\n",
      "675 674\n",
      "674 673\n",
      "673 672\n",
      "672 671\n",
      "671 670\n",
      "670 669\n",
      "669 668\n",
      "668 667\n",
      "667 666\n",
      "666 665\n",
      "665 664\n",
      "664 663\n",
      "663 662\n",
      "662 661\n",
      "661 660\n",
      "660 659\n",
      "659 658\n",
      "658 657\n",
      "657 656\n",
      "656 655\n",
      "655 654\n",
      "654 653\n",
      "653 652\n",
      "652 651\n",
      "651 650\n",
      "650 649\n",
      "649 648\n",
      "648 647\n",
      "647 646\n",
      "646 645\n",
      "645 644\n",
      "644 643\n",
      "643 642\n",
      "642 641\n",
      "641 640\n",
      "640 639\n",
      "639 638\n",
      "638 637\n",
      "637 636\n",
      "636 635\n",
      "635 634\n",
      "634 633\n",
      "633 632\n",
      "632 631\n",
      "631 630\n",
      "630 629\n",
      "629 628\n",
      "628 627\n",
      "627 626\n",
      "626 625\n",
      "625 624\n",
      "624 623\n",
      "623 622\n",
      "622 621\n",
      "621 620\n",
      "620 619\n",
      "619 618\n",
      "618 617\n",
      "617 616\n",
      "616 615\n",
      "615 614\n",
      "614 613\n",
      "613 612\n",
      "612 611\n",
      "611 610\n",
      "610 609\n",
      "609 608\n",
      "608 607\n",
      "607 606\n",
      "606 605\n",
      "605 604\n",
      "604 603\n",
      "603 602\n",
      "602 601\n",
      "601 600\n",
      "600 599\n",
      "599 598\n",
      "598 597\n",
      "597 596\n",
      "596 595\n",
      "595 594\n",
      "594 593\n",
      "593 592\n",
      "592 591\n",
      "591 590\n",
      "590 589\n",
      "589 588\n",
      "588 587\n",
      "587 586\n",
      "586 585\n",
      "585 584\n",
      "584 583\n",
      "583 582\n",
      "582 581\n",
      "581 580\n",
      "580 579\n",
      "579 578\n",
      "578 577\n",
      "577 576\n",
      "576 575\n",
      "575 574\n",
      "574 573\n",
      "573 572\n",
      "572 571\n",
      "571 570\n",
      "570 569\n",
      "569 568\n",
      "568 567\n",
      "567 566\n",
      "566 565\n",
      "565 564\n",
      "564 563\n",
      "563 562\n",
      "562 561\n",
      "561 560\n",
      "560 559\n",
      "559 558\n",
      "558 557\n",
      "557 556\n",
      "556 555\n",
      "555 554\n",
      "554 553\n",
      "553 552\n",
      "552 551\n",
      "551 550\n",
      "550 549\n",
      "549 548\n",
      "548 547\n",
      "547 546\n",
      "546 545\n",
      "545 544\n",
      "544 543\n",
      "543 542\n",
      "542 541\n",
      "541 540\n",
      "540 539\n",
      "539 538\n",
      "538 537\n",
      "537 536\n",
      "536 535\n",
      "535 534\n",
      "534 533\n",
      "533 532\n",
      "532 531\n",
      "531 530\n",
      "530 529\n",
      "529 528\n",
      "528 527\n",
      "527 526\n",
      "526 525\n",
      "525 524\n",
      "524 523\n",
      "523 522\n",
      "522 521\n",
      "521 520\n",
      "520 519\n",
      "519 518\n",
      "518 517\n",
      "517 516\n",
      "516 515\n",
      "515 514\n",
      "514 513\n",
      "513 512\n",
      "512 511\n",
      "511 510\n",
      "510 509\n",
      "509 508\n",
      "508 507\n",
      "507 506\n",
      "506 505\n",
      "505 504\n",
      "504 503\n",
      "503 502\n",
      "502 501\n",
      "501 500\n",
      "500 499\n",
      "499 498\n",
      "498 497\n",
      "497 496\n",
      "496 495\n",
      "495 494\n",
      "494 493\n",
      "493 492\n",
      "492 491\n",
      "491 490\n",
      "490 489\n",
      "489 488\n",
      "488 487\n",
      "487 486\n",
      "486 485\n",
      "485 484\n",
      "484 483\n",
      "483 482\n",
      "482 481\n",
      "481 480\n",
      "480 479\n",
      "479 478\n",
      "478 477\n",
      "477 476\n",
      "476 475\n",
      "475 474\n",
      "474 473\n",
      "473 472\n",
      "472 471\n",
      "471 470\n",
      "470 469\n",
      "469 468\n",
      "468 467\n",
      "467 466\n",
      "466 465\n",
      "465 464\n",
      "464 463\n",
      "463 462\n",
      "462 461\n",
      "461 460\n",
      "460 459\n",
      "459 458\n",
      "458 457\n",
      "457 456\n",
      "456 455\n",
      "455 454\n",
      "454 453\n",
      "453 452\n",
      "452 451\n",
      "451 450\n",
      "450 449\n",
      "449 448\n",
      "448 447\n",
      "447 446\n",
      "446 445\n",
      "445 444\n",
      "444 443\n",
      "443 442\n",
      "442 441\n",
      "441 440\n",
      "440 439\n",
      "439 438\n",
      "438 437\n",
      "437 436\n",
      "436 435\n",
      "435 434\n",
      "434 433\n",
      "433 432\n",
      "432 431\n",
      "431 430\n",
      "430 429\n",
      "429 428\n",
      "428 427\n",
      "427 426\n",
      "426 425\n",
      "425 424\n",
      "424 423\n",
      "423 422\n",
      "422 421\n",
      "421 420\n",
      "420 419\n",
      "419 418\n",
      "418 417\n",
      "417 416\n",
      "416 415\n",
      "415 414\n",
      "414 413\n",
      "413 412\n",
      "412 411\n",
      "411 410\n",
      "410 409\n",
      "409 408\n",
      "408 407\n",
      "407 406\n",
      "406 405\n",
      "405 404\n",
      "404 403\n",
      "403 402\n",
      "402 401\n",
      "401 400\n",
      "400 399\n",
      "399 398\n",
      "398 397\n",
      "397 396\n",
      "396 395\n",
      "395 394\n",
      "394 393\n",
      "393 392\n",
      "392 391\n",
      "391 390\n",
      "390 389\n",
      "389 388\n",
      "388 387\n",
      "387 386\n",
      "386 385\n",
      "385 384\n",
      "384 383\n",
      "383 382\n",
      "382 381\n",
      "381 380\n",
      "380 379\n",
      "379 378\n",
      "378 377\n",
      "377 376\n",
      "376 375\n",
      "375 374\n",
      "374 373\n",
      "373 372\n",
      "372 371\n",
      "371 370\n",
      "370 369\n",
      "369 368\n",
      "368 367\n",
      "367 366\n",
      "366 365\n",
      "365 364\n",
      "364 363\n",
      "363 362\n",
      "362 361\n",
      "361 360\n",
      "360 359\n",
      "359 358\n",
      "358 357\n",
      "357 356\n",
      "356 355\n",
      "355 354\n",
      "354 353\n",
      "353 352\n",
      "352 351\n",
      "351 350\n",
      "350 349\n",
      "349 348\n",
      "348 347\n",
      "347 346\n",
      "346 345\n",
      "345 344\n",
      "344 343\n",
      "343 342\n",
      "342 341\n",
      "341 340\n",
      "340 339\n",
      "339 338\n",
      "338 337\n",
      "337 336\n",
      "336 335\n",
      "335 334\n",
      "334 333\n",
      "333 332\n",
      "332 331\n",
      "331 330\n",
      "330 329\n",
      "329 328\n",
      "328 327\n",
      "327 326\n",
      "326 325\n",
      "325 324\n",
      "324 323\n",
      "323 322\n",
      "322 321\n",
      "321 320\n",
      "320 319\n",
      "319 318\n",
      "318 317\n",
      "317 316\n",
      "316 315\n",
      "315 314\n",
      "314 313\n",
      "313 312\n",
      "312 311\n",
      "311 310\n",
      "310 309\n",
      "309 308\n",
      "308 307\n",
      "307 306\n",
      "306 305\n",
      "305 304\n",
      "304 303\n",
      "303 302\n",
      "302 301\n",
      "301 300\n",
      "300 299\n",
      "299 298\n",
      "298 297\n",
      "297 296\n",
      "296 295\n",
      "295 294\n",
      "294 293\n",
      "293 292\n",
      "292 291\n",
      "291 290\n",
      "290 289\n",
      "289 288\n",
      "288 287\n",
      "287 286\n",
      "286 285\n",
      "285 284\n",
      "284 283\n",
      "283 282\n",
      "282 281\n",
      "281 280\n",
      "280 279\n",
      "279 278\n",
      "278 277\n",
      "277 276\n",
      "276 275\n",
      "275 274\n",
      "274 273\n",
      "273 272\n",
      "272 271\n",
      "271 270\n",
      "270 269\n",
      "269 268\n",
      "268 267\n",
      "267 266\n",
      "266 265\n",
      "265 264\n",
      "264 263\n",
      "263 262\n",
      "262 261\n",
      "261 260\n",
      "260 259\n",
      "259 258\n",
      "258 257\n",
      "257 256\n",
      "256 255\n",
      "255 254\n",
      "254 253\n",
      "253 252\n",
      "252 251\n",
      "251 250\n",
      "250 249\n",
      "249 248\n",
      "248 247\n",
      "247 246\n",
      "246 245\n",
      "245 244\n",
      "244 243\n",
      "243 242\n",
      "242 241\n",
      "241 240\n",
      "240 239\n",
      "239 238\n",
      "238 237\n",
      "237 236\n",
      "236 235\n",
      "235 234\n",
      "234 233\n",
      "233 232\n",
      "232 231\n",
      "231 230\n",
      "230 229\n",
      "229 228\n",
      "228 227\n",
      "227 226\n",
      "226 225\n",
      "225 224\n",
      "224 223\n",
      "223 222\n",
      "222 221\n",
      "221 220\n",
      "220 219\n",
      "219 218\n",
      "218 217\n",
      "217 216\n",
      "216 215\n",
      "215 214\n",
      "214 213\n",
      "213 212\n",
      "212 211\n",
      "211 210\n",
      "210 209\n",
      "209 208\n",
      "208 207\n",
      "207 206\n",
      "206 205\n",
      "205 204\n",
      "204 203\n",
      "203 202\n",
      "202 201\n",
      "201 200\n",
      "200 199\n",
      "199 198\n",
      "198 197\n",
      "197 196\n",
      "196 195\n",
      "195 194\n",
      "194 193\n",
      "193 192\n",
      "192 191\n",
      "191 190\n",
      "190 189\n",
      "189 188\n",
      "188 187\n",
      "187 186\n",
      "186 185\n",
      "185 184\n",
      "184 183\n",
      "183 182\n",
      "182 181\n",
      "181 180\n",
      "180 179\n",
      "179 178\n",
      "178 177\n",
      "177 176\n",
      "176 175\n",
      "175 174\n",
      "174 173\n",
      "173 172\n",
      "172 171\n",
      "171 170\n",
      "170 169\n",
      "169 168\n",
      "168 167\n",
      "167 166\n",
      "166 165\n",
      "165 164\n",
      "164 163\n",
      "163 162\n",
      "162 161\n",
      "161 160\n",
      "160 159\n",
      "159 158\n",
      "158 157\n",
      "157 156\n",
      "156 155\n",
      "155 154\n",
      "154 153\n",
      "153 152\n",
      "152 151\n",
      "151 150\n",
      "150 149\n",
      "149 148\n",
      "148 147\n",
      "147 146\n",
      "146 145\n",
      "145 144\n",
      "144 143\n",
      "143 142\n",
      "142 141\n",
      "141 140\n",
      "140 139\n",
      "139 138\n",
      "138 137\n",
      "137 136\n",
      "136 135\n",
      "135 134\n",
      "134 133\n",
      "133 132\n",
      "132 131\n",
      "131 130\n",
      "130 129\n",
      "129 128\n",
      "128 127\n",
      "127 126\n",
      "126 125\n",
      "125 124\n",
      "124 123\n",
      "123 122\n",
      "122 121\n",
      "121 120\n",
      "120 119\n",
      "119 118\n",
      "118 117\n",
      "117 116\n",
      "116 115\n",
      "115 114\n",
      "114 113\n",
      "113 112\n",
      "112 111\n",
      "111 110\n",
      "110 109\n",
      "109 108\n",
      "108 107\n",
      "107 106\n",
      "106 105\n",
      "105 104\n",
      "104 103\n",
      "103 102\n",
      "102 101\n",
      "101 100\n",
      "100 99\n",
      "99 98\n",
      "98 97\n",
      "97 96\n",
      "96 95\n",
      "95 94\n",
      "94 93\n",
      "93 92\n",
      "92 91\n",
      "91 90\n",
      "90 89\n",
      "89 88\n",
      "88 87\n",
      "87 86\n",
      "86 85\n",
      "85 84\n",
      "84 83\n",
      "83 82\n",
      "82 81\n",
      "81 80\n",
      "80 79\n",
      "79 78\n",
      "78 77\n",
      "77 76\n",
      "76 75\n",
      "75 74\n",
      "74 73\n",
      "73 72\n",
      "72 71\n",
      "71 70\n",
      "70 69\n",
      "69 68\n",
      "68 67\n",
      "67 66\n",
      "66 65\n",
      "65 64\n",
      "64 63\n",
      "63 62\n",
      "62 61\n",
      "61 60\n",
      "60 59\n",
      "59 58\n",
      "58 57\n",
      "57 56\n",
      "56 55\n",
      "55 54\n",
      "54 53\n",
      "53 52\n",
      "52 51\n",
      "51 50\n",
      "50 49\n",
      "49 48\n",
      "48 47\n",
      "47 46\n",
      "46 45\n",
      "45 44\n",
      "44 43\n",
      "43 42\n",
      "42 41\n",
      "41 40\n",
      "40 39\n",
      "39 38\n",
      "38 37\n",
      "37 36\n",
      "36 35\n",
      "35 34\n",
      "34 33\n",
      "33 32\n",
      "32 31\n",
      "31 30\n",
      "30 29\n",
      "29 28\n",
      "28 27\n",
      "27 26\n",
      "26 25\n",
      "25 24\n",
      "24 23\n",
      "23 22\n",
      "22 21\n",
      "21 20\n",
      "20 19\n",
      "19 18\n",
      "18 17\n",
      "17 16\n",
      "16 15\n",
      "15 14\n",
      "14 13\n",
      "13 12\n",
      "12 11\n",
      "11 10\n",
      "10 9\n",
      "9 8\n",
      "8 7\n",
      "7 6\n",
      "6 5\n",
      "5 4\n",
      "4 3\n",
      "3 2\n",
      "2 1\n",
      "1 0\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(\n",
    "    batch_size,\n",
    "    channels,\n",
    "    image_size,\n",
    "    image_size,\n",
    "    dtype=torch.float\n",
    ")\n",
    "\n",
    "x = x.float()\n",
    "x = x.to(device)\n",
    "\n",
    "seq = range(1, num_diffusion_timesteps)\n",
    "noise_arr = []\n",
    "std_arr = []\n",
    "with torch.no_grad():\n",
    "    n = x.size(0)\n",
    "    seq_next = [0] + list(seq[:-1])\n",
    "    x0_preds, xs, x_last = [], [x], []\n",
    "    xt_next = x\n",
    "    times = list(zip(reversed(seq), reversed(seq_next)))\n",
    "    for i,j in times:\n",
    "        print(i, j)\n",
    "\n",
    "        t = (torch.ones(n) * i).to(x.device)\n",
    "        next_t = (torch.ones(n) * j).to(x.device)\n",
    "        at = compute_alpha(betas, t.long())\n",
    "        at_next = compute_alpha(betas, next_t.long())\n",
    "        \n",
    "        xt = xt_next\n",
    "        et, times, ldj = model(xt, t.float())\n",
    "\n",
    "        x0_t = (xt - et * (1 - at).sqrt()) / at.sqrt()\n",
    "        \n",
    "        c1 = eta * ((1 - at / at_next) * (1 - at_next) / (1 - at)).sqrt()\n",
    "        c2 = ((1 - at_next) - c1**2).sqrt()\n",
    "        xt_next = at_next.sqrt() * x0_t + c1 * torch.normal(0, 1, size=x.size()).to(device) + c2 * et"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 302
    },
    "id": "3As4KLEHfZp3",
    "outputId": "9c0a94b7-25ea-4e5c-c677-35ea0b21df50"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f530be8f250>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(xt[0].cpu().numpy().T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 320
    },
    "id": "zMClVpcbJwji",
    "outputId": "d83e35e1-e7c7-47b5-ba6e-f1ade81ebefd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: RuntimeWarning: divide by zero encountered in log\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f5356fa5d10>]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "plt.plot(np.array(entropy_arr))\n",
    "plt.plot(np.log(energy_arr))\n",
    "plt.plot(np.log(mse_arr))\n",
    "plt.plot(np.log(loss_arr - min(loss_arr)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "Vfgg_juz4cat",
    "outputId": "e4f3b8a7-b3a0-4167-d5aa-8a656098842f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(15.1628, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(14.9834, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(14.9746, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(15.0408, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(15.0046, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(15.0414, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(15.0258, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(14.9799, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(15.0080, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(14.9945, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(14.8840, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(14.8557, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(14.9312, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(14.8907, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(14.7849, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(14.8630, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(14.8004, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(14.6783, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(14.6588, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(14.8011, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(14.6414, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(14.6780, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(14.7042, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(14.6543, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(14.7253, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(14.6110, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(14.6831, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(14.6192, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(14.5498, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(14.6177, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(14.6191, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(14.6244, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(14.5291, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(14.5724, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(14.6799, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(14.5436, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(14.5124, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(14.4257, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(14.4829, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(14.5261, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(14.3833, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(14.4134, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(14.3788, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(14.4816, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(14.4508, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(14.4282, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(14.3690, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(14.4070, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(14.3926, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(14.2360, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(14.2419, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(14.2582, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(14.1728, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(14.3307, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(14.2155, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(14.4698, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(14.2878, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(14.1726, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(14.2908, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(14.1698, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(14.2636, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(14.0008, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(14.0672, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(14.1101, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(14.1144, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(14.0917, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(14.0263, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(14.0006, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(14.0315, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(14.1412, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(14.0454, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(13.8693, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(14.0272, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(13.9523, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(14.0044, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(13.9210, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(14.0040, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(14.0287, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(13.9828, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(14.1129, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(13.9903, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(13.8149, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(14.0607, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(13.9809, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(14.0078, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(13.9242, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(13.7653, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(13.8937, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(13.8634, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(13.8035, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(13.7040, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(13.8105, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(13.8096, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(13.8910, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(13.8322, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(13.7929, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(13.7581, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(13.8401, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(13.8563, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(13.5945, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(13.7880, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(13.7599, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(13.6493, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(13.7128, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(13.6239, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(13.7653, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(13.6292, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(13.6043, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(13.6862, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(13.6666, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(13.3736, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(13.4960, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(13.6137, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(13.5650, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(13.3582, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(13.4016, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(13.5338, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(13.4146, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(13.3685, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(13.2512, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(13.4614, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(13.3170, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(13.3622, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(13.4751, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(13.3223, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(13.3608, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(13.3671, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(13.2881, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(13.2341, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(13.0855, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(13.2609, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(13.0724, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(13.2060, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(13.2519, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(12.9515, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(13.1488, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(13.0527, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(13.0374, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(13.1618, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(13.0420, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(12.9637, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(13.0428, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(13.0064, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(12.9938, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(12.9413, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(13.0201, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(13.0076, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(12.8708, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(12.9038, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(12.9130, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(13.0091, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(12.9031, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(12.8219, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(12.8558, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(12.9143, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(12.8287, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(12.9929, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(12.9965, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(12.6272, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(12.8929, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(12.8297, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(12.9663, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(12.7429, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(12.6031, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(12.8085, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(12.6831, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(12.7782, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(12.7040, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(12.7048, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(12.6948, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(12.5002, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(12.7026, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(12.7643, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(12.6844, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(12.6970, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(12.6678, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(12.4577, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(12.6677, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(12.4426, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(12.5321, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(12.5351, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(12.4653, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(12.5366, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(12.4782, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(12.3368, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(12.5804, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(12.5748, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(12.4142, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(12.4279, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(12.4725, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(12.3543, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(12.2701, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(12.1580, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(12.4017, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(12.2135, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(12.3289, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(11.9544, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(12.2536, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(12.2520, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(12.2861, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(12.1424, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(12.1158, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(12.2377, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(12.1932, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(12.0047, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(12.1052, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(12.0013, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(12.0175, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(11.9788, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(11.9095, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(12.0434, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(11.7982, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(12.0493, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(11.9592, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(11.7600, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(11.9563, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(11.6987, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(11.7769, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(11.9635, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(11.7220, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(11.7831, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(11.8131, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(11.8654, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(11.8325, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(11.6446, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(11.8269, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(11.8357, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(11.6744, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(11.4893, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(11.6414, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(11.4452, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(11.6437, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(11.9230, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(11.4998, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(11.6280, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(11.3885, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(11.6357, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(11.5665, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(11.6423, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(11.6008, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(11.4525, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(11.2707, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(11.5253, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(11.4637, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(11.3572, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(11.5099, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(11.3182, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(11.5425, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(11.3266, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(11.4735, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(11.3662, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(11.1047, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(11.1722, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(11.3453, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(11.1282, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(11.3190, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(11.4264, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(11.2500, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(11.2433, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(11.1313, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(11.3793, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(11.1415, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(11.2886, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(11.3309, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(11.2244, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(11.0516, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(10.6844, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(10.8782, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(11.0620, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(11.0550, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(11.0204, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(11.1088, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(10.8579, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(10.9687, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(10.8508, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(10.9951, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(10.8954, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(10.7352, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(10.8006, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(10.6690, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(10.8316, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(10.8043, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(10.6092, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(10.9646, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(10.7247, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(10.7177, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(10.6606, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(10.6084, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(10.8720, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(10.5807, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(10.4428, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(10.5649, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(10.8786, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(10.6593, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(10.7422, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(10.7201, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(10.4038, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(10.7404, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(10.8637, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(10.3072, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(10.7900, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(10.5997, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(10.3409, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(10.3633, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(10.4385, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(10.4746, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(10.5225, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(10.3910, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(10.3599, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(10.3506, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(10.4193, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(10.4867, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(10.3542, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(10.3184, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(10.5604, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(10.2874, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(10.1246, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(10.1591, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(9.9686, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(10.0450, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(9.9411, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(10.2047, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(10.0452, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(9.9706, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(9.8621, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(9.9705, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(10.1987, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(9.8482, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(10.0174, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(9.9749, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(9.9431, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(9.9084, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(9.9260, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(10.0738, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(9.9719, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(10.0310, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(10.0740, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(9.8892, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(9.6098, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(9.6896, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(9.7001, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(9.7864, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(9.7962, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(10.0488, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(9.6148, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(9.6810, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(9.4875, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(9.5223, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(9.3780, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(10.0447, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(9.4190, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(9.4679, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(9.4265, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(9.6681, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(9.6967, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(9.4510, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(9.4263, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(9.4852, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(9.5048, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(9.3005, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(9.3222, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(9.3717, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(9.1027, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(9.1814, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(9.3757, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(9.1827, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(9.3364, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(8.9530, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(9.4112, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(9.2524, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(9.1251, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(9.3237, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(9.2045, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(9.1039, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(9.1458, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(9.1650, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(8.8615, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(8.9895, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(9.2398, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(9.0850, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(9.0153, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(9.0420, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(8.7944, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(9.1483, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(9.0111, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(9.0380, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(8.9839, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(8.9805, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(9.0544, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(8.8666, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(8.8254, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(8.6690, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(8.7291, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(8.6269, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(8.8799, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(8.7318, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(8.7973, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(8.8788, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(8.7257, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(8.6492, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(8.5903, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(8.5120, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(8.7841, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(8.8489, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(8.7623, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(8.6704, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(8.3227, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(8.2922, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(8.4019, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(8.5381, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(8.8114, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(8.5128, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(8.4687, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(8.5096, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(8.1984, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(8.3586, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(8.1892, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(8.4343, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(8.3452, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(8.3489, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(8.5122, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(8.2935, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(8.7246, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(8.3927, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(8.2719, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(8.3354, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(7.9480, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(7.9329, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(8.3155, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(8.1250, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(8.4896, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(8.2593, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(8.0257, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(8.2430, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(7.9383, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(8.0648, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(8.0448, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(8.1474, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(8.2759, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(8.2302, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(8.1558, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(7.7219, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(8.0376, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(8.0854, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(7.9833, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(7.9863, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(7.8519, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(7.8227, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(7.7611, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(7.8246, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(7.6646, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(7.9023, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(7.8684, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(7.6231, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(7.7133, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(7.8692, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(7.5707, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(7.9357, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(7.8404, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(7.7722, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(7.8426, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(7.7512, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(7.2716, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(7.6192, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(7.5238, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(7.5198, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(7.3423, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(7.3528, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(7.4470, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(7.3879, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(7.5005, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(7.2681, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(7.5732, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(7.7247, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(7.5673, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(7.1623, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(7.2934, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(7.2515, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(7.5382, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(7.2979, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(7.2975, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(7.2905, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(7.5103, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(7.3077, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(7.2902, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(7.5031, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(7.3785, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(7.1014, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(6.9367, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(7.1876, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(7.1423, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(7.1442, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(7.2060, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(7.1786, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(7.2037, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(7.1613, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(7.0785, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(7.0422, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(6.9892, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(7.0238, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(7.0448, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(7.0103, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(7.1139, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(6.9456, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(6.9052, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(7.0378, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(6.8896, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(6.8316, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(6.6878, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(6.8614, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(6.9468, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(6.8752, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(6.5386, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(6.7953, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(6.9365, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(6.7544, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(6.6547, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(6.6930, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(6.4587, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(6.4552, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(6.6070, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(6.8093, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(6.5159, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(6.6001, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(6.6841, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(6.9189, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(6.6580, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(6.5583, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(6.6199, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(6.3702, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(6.5964, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(6.6175, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(6.5726, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(6.4349, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(6.4739, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(6.2810, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(6.5155, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(6.2599, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(6.2334, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(6.3505, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(6.3372, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(6.4567, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(6.3437, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(6.5759, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(6.5432, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(6.2307, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(6.2492, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(6.2326, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(6.4964, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(6.1218, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(6.1750, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(6.2448, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(6.2849, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(6.1315, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(6.2418, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(6.5314, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(6.2104, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(6.4474, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(6.1506, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(6.1728, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(6.2052, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(5.9679, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(6.0886, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(6.2525, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(5.9070, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(5.7435, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(6.1609, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(5.8751, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(5.9998, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(5.8872, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(5.7864, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(5.7960, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(5.8339, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(6.0100, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(6.0366, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(5.6115, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(5.7307, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(5.7618, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(5.5207, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(5.7655, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(5.7533, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(5.9706, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(5.8700, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(5.7692, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(5.5868, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(5.7203, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(5.7624, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(5.7484, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(5.5519, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(5.5219, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(5.6813, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(5.6475, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(5.4821, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(5.8102, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(5.5672, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(5.4777, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(5.5311, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(5.5316, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(5.6324, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(5.6923, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(5.7631, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(5.2669, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(5.4261, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(5.5392, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(5.6306, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(5.3744, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(5.3528, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(5.5333, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(5.2629, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(5.3441, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(5.4056, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(5.4785, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(5.4990, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(5.3022, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(5.3315, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(5.2116, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(5.3160, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(5.0718, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(5.0832, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(5.3163, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(5.3195, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(5.0242, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(5.1290, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(5.1654, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(5.1488, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(5.0889, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(5.0956, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(5.2038, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(5.2284, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(5.3175, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(5.1037, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(5.0145, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(5.2128, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(4.9790, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(5.1615, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(5.0522, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(5.0002, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(5.1694, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(4.8017, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(4.8870, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(5.0872, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(5.0231, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(4.9144, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(4.7030, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(4.7353, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(4.9365, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(5.0477, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(5.0646, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(4.7803, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(5.0032, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(4.8426, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(4.8615, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(4.7179, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(4.9581, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(5.0737, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(4.8993, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(4.6448, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(4.8350, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(4.8031, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(4.7256, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(4.7712, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(4.6660, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(4.9160, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(4.9285, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(4.3932, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(4.7622, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(4.4508, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(4.6722, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(4.6147, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(4.5549, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(4.5109, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(4.6017, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(4.3053, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(4.7015, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(4.6450, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(4.4033, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(4.5308, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(4.8285, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(4.3329, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(4.2436, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(4.4315, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(4.6501, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(4.5320, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(4.6851, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(4.6544, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(4.4661, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(4.2239, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(4.3857, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(4.3081, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(4.5431, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(4.4008, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(4.5148, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(4.4278, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(4.3052, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(4.2069, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(4.4497, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(4.4492, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(4.3519, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(4.2382, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(4.2176, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(4.3442, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(4.3632, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(4.1798, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(4.1212, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(4.3122, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(4.2504, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(4.0955, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(3.7899, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(4.1939, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(4.4626, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(4.2440, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(4.3875, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(4.2122, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(4.1897, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(4.0325, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(4.0189, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(4.1538, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(3.9409, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(4.2397, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(4.2564, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(4.0273, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(4.1714, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(4.0347, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(3.8045, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(3.8800, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(3.7325, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(4.1903, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(4.0839, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(3.9839, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(3.7947, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(4.0415, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(3.9430, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(3.6951, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(4.1254, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(4.0977, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(3.9792, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(3.9188, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(4.0756, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(3.9976, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(3.9497, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(3.9433, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(3.8872, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(3.9740, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(3.7774, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(4.0295, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(3.6220, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(3.6900, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(3.9797, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(3.9802, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(3.3818, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(3.7120, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(3.7567, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(3.5049, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(3.3264, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(3.8302, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(3.6834, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(3.9862, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(3.8322, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(3.6970, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(3.5227, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(3.9152, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(3.7118, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(3.6477, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(3.8198, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(3.6086, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(3.5508, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(3.3684, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(3.5206, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(3.6938, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(3.6804, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(3.4330, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(3.2834, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(3.7347, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(3.6543, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(3.5366, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(3.7223, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(3.3786, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(3.5270, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(3.3964, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(3.4112, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(3.5970, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(3.7003, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(3.8551, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(3.4790, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(3.5207, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(3.6604, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(3.2640, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(3.5662, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(3.3128, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(3.3975, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(3.4153, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(3.3276, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(3.1562, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(3.2847, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(3.3209, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(3.5264, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(3.1418, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(3.3619, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(3.1245, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(3.4772, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(3.4562, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(3.0831, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(3.0339, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(3.4719, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(3.2345, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(3.3012, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(3.2099, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(3.3445, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(3.1125, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(3.4167, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(3.1841, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(3.1478, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(3.2889, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.9829, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.9815, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(3.2015, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(3.1009, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(3.1030, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(3.2476, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(3.2125, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(3.2454, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(3.2809, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(3.0865, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.9412, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(3.0688, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(3.2779, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(3.1232, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.8526, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(3.1046, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(3.1213, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(3.1373, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(3.0952, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.9516, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(3.0873, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(3.0112, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.9434, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.8742, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(3.1017, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.6237, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.9057, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(3.1810, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(3.0779, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(3.2657, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.9675, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(3.0551, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.7495, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.9043, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.9764, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.8834, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.9651, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(3.1415, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.8949, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.9732, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.9569, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.7764, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(3.1338, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.4836, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.9296, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.8064, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.6397, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(3.0804, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.7716, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.8668, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(3.1515, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.9327, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.8306, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.8489, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.6662, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.7326, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.8830, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.7057, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.8106, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.7913, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.5346, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.5652, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.8182, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.7981, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.8323, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.6728, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.6402, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.8670, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.5161, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.4239, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.6721, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.5027, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.8324, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.7775, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.6159, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.5148, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.6997, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.8039, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.5342, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.7349, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.3450, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.5699, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.6032, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.5029, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.5650, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.7900, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.5813, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.4293, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.8474, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.4528, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.5979, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.3351, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.6716, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.5694, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.5671, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.4819, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.3926, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.4663, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.4339, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.3969, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.3994, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2132, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.4695, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2006, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.5760, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.3994, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.3547, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1725, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2894, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.4022, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.5716, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2659, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.4582, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2822, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2679, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1478, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2905, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.3860, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2907, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1143, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2293, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.3087, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.3169, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.3266, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2701, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.3557, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1727, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.4117, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2242, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.3751, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.5052, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.5532, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.3414, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1556, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.3064, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2931, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1387, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2927, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1883, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.0755, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(1.8635, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.0440, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1472, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.0881, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.4723, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(1.9411, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.4503, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.0122, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1954, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1665, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2262, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1792, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1596, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1266, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2281, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(1.8370, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1791, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.0644, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(1.9494, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(1.6973, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(1.8917, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.0747, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.4717, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(1.8694, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(1.8850, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.0670, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(1.7136, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(1.8000, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(1.8846, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.0225, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(1.8875, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(1.6412, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(1.6995, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(1.8935, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.0390, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(1.9141, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(1.9357, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(1.6814, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.0957, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(1.6502, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.0410, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.0265, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(1.7180, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(1.8420, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(1.9973, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(1.7269, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.0446, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2101, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(1.7038, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(1.9912, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(1.7140, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(1.9056, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.2166, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.0359, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(1.8235, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1235, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(1.9953, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(1.8015, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(1.9239, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1467, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(1.9443, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(1.7190, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(1.7807, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(1.8520, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(1.7236, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(1.8826, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(1.7235, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(1.9106, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(1.9580, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(1.5450, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(1.7660, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(1.7643, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(1.8848, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.0346, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(1.7102, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(1.6387, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(2.1864, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(1.8596, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(1.7052, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(1.7955, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(1.7493, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(1.5518, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(1.5204, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(1.6266, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(1.7935, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(1.7963, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(1.8761, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(1.4722, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(1.6638, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(1.5402, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(1.7339, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(1.9186, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(1.7640, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(1.7202, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(1.8006, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(1.6291, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(1.6256, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(1.6542, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(1.6495, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(1.7216, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(1.6255, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(1.7265, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(1.8377, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(1.4534, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(1.5053, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(1.6772, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(1.5364, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(1.7063, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(1.5413, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(1.4459, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(1.3934, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(1.6647, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(1.6210, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(1.5247, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(1.5550, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(1.6668, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(1.6692, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(1.6564, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(1.5632, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(1.6749, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(1.2578, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(1.2229, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(1.4159, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(1.6640, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(1.2406, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(1.5952, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(1.5706, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(1.2318, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(1.3435, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(1.2502, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(1.2715, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(1.6392, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(1.5803, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(1.3110, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(1.8273, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(1.3017, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(1.3766, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(1.3324, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(1.3338, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(1.3768, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(1.4117, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(1.7048, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(1.3688, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(1.5857, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(1.3891, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(1.6778, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(1.2662, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(1.4939, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(1.3386, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(1.2997, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(1.5446, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(1.1556, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(1.4249, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(1.3024, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(1.4953, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(1.2287, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(1.2160, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(1.1746, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(1.5019, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(1.2382, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(1.3275, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(1.5641, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(1.3624, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(1.3447, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(1.3914, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(1.3294, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(1.0074, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(1.1980, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.9998, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(1.0338, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(1.2142, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(1.1549, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(1.4760, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(1.3684, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(1.3074, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.9508, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(1.2835, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(1.2028, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(1.4901, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(1.2979, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(1.3412, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(1.1359, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(1.0854, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(1.1079, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(1.1645, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(1.2042, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(1.0074, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(1.2619, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(1.3378, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(1.1871, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.9536, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(1.0571, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(1.0706, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(1.2222, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(1.0983, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(1.2896, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(1.0912, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(1.2982, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.9907, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(1.2342, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(1.0716, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(1.0508, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(1.1231, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(1.1962, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(1.2208, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(1.0966, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(1.1345, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(1.1553, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.9596, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.8989, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(1.3244, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(1.0049, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(1.0616, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(1.0816, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.9838, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(1.2314, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(1.1463, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.9826, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.7938, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(1.0359, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.9806, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(1.1680, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(1.3163, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.8306, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.9420, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.7816, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(1.1254, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(1.1290, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(1.1058, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(1.2035, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.9454, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.9802, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.8083, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(1.2802, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(1.1849, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(1.1449, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(1.1283, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.8998, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(1.0518, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.8303, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.8533, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.8670, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.9882, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.8665, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.6984, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.9188, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(1.0302, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(1.0091, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(1.0249, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(1.0953, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(1.0590, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.8026, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.8579, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(1.1779, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.7610, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.8841, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.9007, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.7339, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.7577, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.7753, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.8689, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.7801, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.7510, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.7486, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.8156, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.7087, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.6271, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.9378, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.7169, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.8322, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.9676, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.6933, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.9340, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.8423, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.8484, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.7442, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.6292, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.7994, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.4355, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.9092, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.8683, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.7780, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.9610, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.6538, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.8773, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.5831, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.7709, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.7034, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.5688, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.6644, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.8736, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.8335, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.7878, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.7043, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.6231, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.7666, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.6415, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.8955, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.6975, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.8562, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.8861, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.5237, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.6352, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.8376, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.7919, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.6149, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.7659, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.9174, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.8133, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.5646, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.6205, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.5416, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.6226, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.5386, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.8529, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.6990, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.5834, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.7959, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.5630, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.6490, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.8327, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.4562, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.9968, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.4942, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.3847, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.6968, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.4541, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.5042, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.7152, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.5912, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.5024, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.8289, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.5233, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.7103, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.6889, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.4674, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.5551, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.4893, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.3364, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.7976, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.5395, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.5782, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.6556, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.4274, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.4867, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.5196, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.6953, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.3774, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.4801, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.6582, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.3236, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.5951, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.6478, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.4584, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.4915, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.3358, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.6867, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.4951, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.5715, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.7026, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.5054, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.5403, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.6768, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.8129, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.4501, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.6845, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.3198, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.5592, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.5966, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.0815, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.5406, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.6012, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.3311, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.3566, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.4185, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.5827, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.3930, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.3866, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.4654, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.4188, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.3486, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.2764, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.2610, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.3105, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.3374, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.3941, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.0074, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.4162, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.5034, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.5017, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.5149, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.4222, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.4336, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.1692, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.3282, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.3777, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.1467, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.4728, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.3639, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.3428, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.1740, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.5907, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.3954, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.4904, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.3157, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.2329, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.4010, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.0981, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.4380, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.3379, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.4768, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.3107, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.3067, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.5134, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.3960, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.4059, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.4324, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.2615, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.2738, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.0186, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.1114, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.3782, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.1883, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.2975, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.2135, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.2103, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.3500, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.2372, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.0868, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.4990, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.2618, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.4390, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.2135, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.4746, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.2478, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.0852, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.2143, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.3475, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.2058, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.1033, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.1385, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.1664, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.1690, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.3088, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.0240, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.2681, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.0324, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.2375, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.0269, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.1866, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.1938, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.2048, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.0735, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.1236, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.1081, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.0160, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.0431, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.0830, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.2072, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.0162, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.2335, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.1279, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.0064, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.1538, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.3060, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.0707, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.0472, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.0291, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.0918, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.1288, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.2289, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.0886, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.0983, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.1213, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.0156, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.1480, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.4223, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.1613, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.0828, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.0324, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.0921, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.0676, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.0657, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.0608, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.0012, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.3364, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.2693, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.0877, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.0059, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.1474, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.1085, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.1227, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.0908, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.0307, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.3417, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.0042, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.0118, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.1477, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.0882, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.0270, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.0559, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.1041, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.0938, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.0212, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.2576, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.1276, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.1339, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.1930, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.0735, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.0201, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.2251, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.0411, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.0790, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.0999, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.0417, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.0422, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.0132, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.0961, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.0343, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.1919, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.2173, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.0487, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.3674, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.1493, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.1545, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.3469, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.1140, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.3831, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.3602, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.1162, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.4673, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.2637, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.1695, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.1150, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.1880, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.0961, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.2082, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.1215, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.1187, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.2333, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.2296, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.2204, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.1174, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.1990, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.1419, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.2611, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.2860, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.0168, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.1696, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.2357, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.0794, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.0458, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.5235, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.1845, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.3420, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.1475, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.3141, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.4488, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.5017, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.4113, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.0121, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.2185, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.3142, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.0568, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.3552, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.3637, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.2795, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.1501, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.2665, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.5104, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.2300, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.1601, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.2743, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.3557, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.0366, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.2375, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.1692, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.3287, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.4368, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.1026, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.2165, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.3850, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.4931, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.1129, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.2467, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.3166, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.3476, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.2997, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.5595, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.5730, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.0158, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.4324, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.2868, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.0324, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.4013, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.3534, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.3418, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.2759, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.2712, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.1326, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.2993, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.4938, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.6811, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.2732, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.4829, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.4380, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.4603, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.3651, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.3723, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.3166, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(0.2066, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.1623, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.3002, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.6248, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.3461, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.3252, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.6893, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.2907, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.2380, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.4205, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.5057, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.6217, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.3389, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.5731, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.4381, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.3480, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.4926, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.2555, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.3589, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.4970, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.3596, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.4821, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.4203, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.5454, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.5541, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.4839, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.2437, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.3884, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.3623, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.9127, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.4378, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.3764, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.5647, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.4200, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.5262, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.5478, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.5600, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.4680, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.7777, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.4355, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.5364, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.8136, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.2987, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.7063, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.3712, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.4260, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.7559, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.6093, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.3715, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.6202, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.4059, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.4967, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.3828, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.3956, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.5911, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.7328, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.5499, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.6327, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.5446, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.4837, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.7093, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.7218, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.7324, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.7807, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.6125, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.7147, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.6409, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.7922, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.5657, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.6870, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.7102, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.7250, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.6585, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.4567, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.8017, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.6138, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.5704, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.5568, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.8350, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.9042, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.7047, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.7886, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.7424, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.6063, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.4248, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.5614, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.6345, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.8230, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.7036, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.5341, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.6092, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.5166, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.4853, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.8473, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.5589, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.5813, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.5775, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.7389, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.6722, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.8412, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.8485, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.7248, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.5909, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.8954, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.7585, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.6571, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.7956, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.7977, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.7081, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.8759, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.6757, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.6967, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.6996, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.7645, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.7494, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.7734, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.6162, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.6105, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.7905, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.0475, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.7467, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.7236, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.8537, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.0036, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.6923, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.8411, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.8777, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.6083, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.8012, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.5428, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.6243, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.6174, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.9018, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.8122, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.6499, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.6586, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.7503, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.0816, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.9547, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.8059, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.7074, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.9479, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.6049, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.6983, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.6979, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.9117, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.7718, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.7426, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.8224, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.8651, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.7060, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.8160, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.0885, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.7658, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.0686, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.5728, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.9507, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.8818, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.7412, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.8134, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.7299, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.9774, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.6846, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.8038, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.1710, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.8128, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.8110, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.8738, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.9627, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.0897, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.9772, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.9582, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.9851, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.2113, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.8617, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.7914, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.9355, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.8777, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.9068, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.0038, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.9634, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.7615, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.7251, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.9296, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.6884, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.0070, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.9257, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.9967, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.9462, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.1588, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.7574, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.0236, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.8323, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.0760, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.1812, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.7182, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.8119, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.9608, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.8499, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.9504, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.9579, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.0041, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.6187, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.7466, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.0579, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.0388, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.1441, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.0145, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.0987, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.0164, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.1025, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.8092, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.0142, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.9252, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.0758, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.0001, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.9065, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.0890, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.8811, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.9068, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.1067, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.9034, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.1485, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.1429, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.9882, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.0684, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.2381, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.1971, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.0349, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.0503, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.8966, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.7366, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.0531, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.3051, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.1869, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.2520, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.0935, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.1492, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.1663, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.3016, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.8625, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.0994, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.2119, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.0561, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.2128, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.0160, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.1401, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.1767, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.0495, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.0433, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.9057, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.9901, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.2425, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.1221, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.1035, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.9709, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.1043, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.2493, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.2969, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.1991, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.1672, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.0610, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.9725, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.1684, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.0961, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.2155, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.3514, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.8871, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.2975, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.1612, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.3395, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.1706, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.3822, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.1137, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.0542, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.2304, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.2147, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.3302, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.2007, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.1695, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.2895, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.3031, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.3283, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.1524, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-0.9408, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.1410, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.2625, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.2140, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.2908, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.2581, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.2573, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.0180, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.0202, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.3334, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.2558, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.2826, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.0644, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.2481, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.2738, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.3205, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.2213, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.1952, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.2049, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.2810, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.2492, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.2086, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.3267, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.2194, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.5687, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.3290, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.2590, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.1083, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.1532, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.0819, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.3860, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.2182, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.1428, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.3314, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.2102, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.1803, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.1835, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.0945, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.2489, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.2139, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.4041, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.4579, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.3454, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.2522, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.3143, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.3517, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.2808, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.4593, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.2929, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.2968, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.3144, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.2918, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.3958, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.4244, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.2498, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.4688, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.3118, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.3702, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.3448, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.5745, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.3050, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.4253, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.3829, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.5547, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.3791, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.5200, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.4989, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.4855, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.4456, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.5504, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.4703, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.4165, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.4115, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.5514, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.4842, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.4876, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.3647, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.3923, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.3132, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.3382, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.5498, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.4624, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.3946, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.2783, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.4300, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.4360, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.3711, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.3927, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.2795, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.4881, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.6247, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.4844, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.4401, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.4395, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.3748, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.2364, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.4724, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.3640, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.4111, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.4233, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.3285, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.4754, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.4784, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.7150, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.3727, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.5628, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.5159, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.6077, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.4463, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.4776, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.4923, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.4458, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.4961, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.3977, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.3350, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.4666, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.4578, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.3945, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.4568, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.6534, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.4155, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.4953, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.5807, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.3243, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.4289, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.7825, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.6731, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.4396, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.5327, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.4761, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.6521, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.5713, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.4271, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.5973, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.5527, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.6562, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.5475, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.3915, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.4716, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.5610, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.2934, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.3323, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.5021, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.5055, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.4997, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.4236, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.5545, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.4332, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.5838, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.6323, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.3545, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.6626, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.4510, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.8156, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.5291, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.5208, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.4652, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.5549, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.6879, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.4874, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.6443, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.7396, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.3187, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.7293, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.7250, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.8130, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.6660, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.6040, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.8040, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.6690, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.5386, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.6381, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.7155, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.5955, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.3394, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.5144, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.6882, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.7328, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.7585, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.5450, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.4421, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.5976, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.7463, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.7112, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.8231, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.5543, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.6274, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.9231, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.6516, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.5924, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.3098, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.6119, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.5672, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.8546, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.7531, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.4821, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.5713, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.7193, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.7421, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.7236, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.7459, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.7103, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.7565, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.5837, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.7000, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.5752, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.6597, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.6604, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.8345, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.6765, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.4591, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.0244, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.6509, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.4963, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.7780, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.7778, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.8577, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.5978, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.0624, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.8437, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.7204, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.6629, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.7033, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.7046, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.4608, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.8679, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.8504, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.8834, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.7811, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.4058, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.5252, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.6635, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.8025, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.8432, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.6577, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.7808, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.7749, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.6427, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.6718, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.8702, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.6433, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.8089, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.4825, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.6990, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.8485, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.8446, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.8669, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.7688, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.7343, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.8646, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.7721, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.8585, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.9259, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.0105, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.9071, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.6718, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.7681, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.8646, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.7590, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.7380, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.8194, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.9484, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.0209, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.4516, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.8856, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.7540, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.8233, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.0959, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.7756, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.9330, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.8998, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.0391, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.8856, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.7811, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.7672, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.9615, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.6511, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.7545, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.9710, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.9375, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.9446, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.9286, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.8987, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.8287, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.8538, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.8682, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.8892, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.8258, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.7046, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.8043, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.9925, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.8949, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.9115, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.0801, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.9832, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.9225, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.9797, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.0003, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.9267, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.9592, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.8174, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.9789, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.6789, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.0846, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.0243, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.9559, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.9170, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.0547, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.7661, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.0830, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.7626, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.9076, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.7304, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.1057, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.7246, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.6504, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.9529, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.8705, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.8955, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.0620, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.1120, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.1513, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.1257, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.9779, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.8789, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.0552, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.7776, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.0499, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.9697, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.9812, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.0166, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.8551, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.1451, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.9692, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.8177, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.9836, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.9620, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.2872, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.9717, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.9087, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.9272, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.0443, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.0559, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.9471, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.9607, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.0096, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.0065, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.0463, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.8963, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.0228, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.9999, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.8943, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.9020, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.0653, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.9103, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.0969, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.9826, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.9556, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.8250, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.2213, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.0998, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.8581, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.9499, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.9024, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.0146, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.0350, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.1520, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.0906, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.9830, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.0203, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.0260, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.1979, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.1071, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.9950, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.2421, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.9474, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.8713, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.1354, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.0877, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.0068, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.0158, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.1762, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.9338, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.9931, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.0637, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.9836, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.0300, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.9454, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.2357, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.2000, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.9430, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.0852, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.1807, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.9896, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.2053, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.3304, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.2434, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.1023, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.1544, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.0653, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.1288, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.3371, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.2145, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.0745, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.8640, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.1079, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.8939, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.2128, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.0614, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.1062, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.1798, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.0755, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.2736, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.2352, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.2592, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.1253, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.0913, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.1338, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.9853, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.0184, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.0844, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.9899, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.2518, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.2017, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.1532, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.1437, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.2139, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.0507, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.2505, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.9902, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.0569, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.9328, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.1779, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.1126, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.1552, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.1836, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.0526, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.1051, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.2780, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.1697, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.9629, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.9639, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.3414, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.2422, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.3548, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.2978, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.2034, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.2800, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.2537, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.1320, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.2165, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.0023, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.2579, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.1618, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.1998, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.2637, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.1300, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.1985, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.1675, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.1626, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.3578, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.3642, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.3731, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.4626, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.0605, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.3382, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.2337, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.3012, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.3300, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.2960, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.2042, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.0789, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.2100, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.3235, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.3557, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.2944, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.2863, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.2391, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.3133, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.0712, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.4184, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.2956, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.2411, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.1601, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.0887, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.0847, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.3419, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.2857, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-1.9836, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.1937, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.3472, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.1423, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.0855, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.4135, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.2909, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.4245, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.2853, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.1666, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.0335, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.4573, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.2802, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.2243, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.4068, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.3624, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.4380, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.4370, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.3171, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.1798, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.3447, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.3683, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.3856, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.4186, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.3385, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.4621, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.4491, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.3231, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.3568, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.2559, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.3175, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.3553, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.2184, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.3525, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.3872, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.2912, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.1849, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.2314, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.3161, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.1963, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.1978, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.4741, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.1968, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.3248, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.1022, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.3617, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.2732, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.2906, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.1966, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.2181, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.3967, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.2977, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.4113, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.4126, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.2614, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.2678, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.2061, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.2835, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.5232, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.3801, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.3289, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.4941, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.3327, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.3056, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.4204, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.4308, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.3215, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.3720, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.4986, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.3972, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.3468, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.2599, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.2717, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.3607, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.1850, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.4018, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.4806, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.2811, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.4355, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.4128, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.3601, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.4075, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.3240, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.3211, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.3047, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.2898, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.3803, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.5386, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.5210, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.3887, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.2992, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.4165, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.4635, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.4728, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.3976, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.5462, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.4728, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.3705, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.2501, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.4218, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.3973, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.2871, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.5007, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.4621, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.4199, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.5414, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.4829, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.5469, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.4956, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.4262, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.3927, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.3914, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.4643, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.4119, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.5242, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.5378, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.3949, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.3676, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.5200, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.4663, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.3967, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.5047, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.2387, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.3513, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.4480, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.3374, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.4197, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.4659, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.3504, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.3253, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.2814, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.5331, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.4448, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.4997, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.5950, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.4783, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.4244, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.5233, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.2270, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.3502, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.5584, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.5503, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.1539, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.4488, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.4201, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.5069, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.4648, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.6082, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.3387, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.5037, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.4684, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.3971, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.5606, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.4569, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.6197, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.4269, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.4587, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.5381, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.4474, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.6029, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.6211, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.5872, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.4888, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.5451, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.4842, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.6387, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.7305, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.5344, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.3421, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.4789, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.4892, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.5163, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.4669, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.4714, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.5148, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.5745, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.6725, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.5497, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.6705, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.5890, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.5755, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.6995, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.5904, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.4237, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.6192, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.5361, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.5109, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.4396, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.5732, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.5632, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.6747, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.6633, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.5915, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.6598, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.6690, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.6224, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.5279, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.5943, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.5080, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.6239, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.7455, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.5317, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.6576, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.6850, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.5134, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.4612, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.5343, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.5817, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.6304, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.7614, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.6483, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.5403, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.5399, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.7609, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.5743, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.6471, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.5943, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.5616, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.7839, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.7457, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.5989, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.7777, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.6851, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.6161, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.7679, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.6555, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.5765, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.7197, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.7256, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.4924, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.7028, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.6915, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.8147, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.5247, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.6278, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.5163, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.6094, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.6213, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.5503, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.4170, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.8770, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.5896, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.6301, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.6437, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.6225, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.8212, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.5960, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.7853, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.7069, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.8232, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.6585, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.7686, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.5634, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.6931, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.5297, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.6495, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.6808, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.6423, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.6060, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.6443, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.6563, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.6738, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.6358, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.7781, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.5201, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.6563, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.7759, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.7491, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.6579, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.5238, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.6384, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.6729, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.7426, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.5916, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.7376, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.7440, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.7987, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.5939, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.6430, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.6838, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.7056, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.6690, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.6357, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.5092, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.7527, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.7955, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.7984, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.8021, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.7690, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.7699, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.9237, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.7883, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.6384, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.7780, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.7057, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.7360, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.7697, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.6862, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.7405, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.6983, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.7268, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.8131, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.6828, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.7734, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.8116, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.6368, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.7651, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.7026, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.6810, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.5727, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.7543, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.8212, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.6584, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.8054, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.8111, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.5444, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.8740, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.8934, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.6864, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.7261, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.8943, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.8496, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.6984, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.8001, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.8089, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.8299, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.7137, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.8250, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.8496, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.7609, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.7886, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.7769, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.6526, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.8863, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.7853, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.8095, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.8732, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.6063, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.7910, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.7374, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.8982, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.7746, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.8328, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.8059, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.9167, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.8523, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.8009, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.9759, device='cuda:0', grad_fn=<SubBackward0>)\n",
      "tensor(-2.9001, device='cuda:0', grad_fn=<SubBackward0>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-903387d70f3e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0menergy_curve\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menergy_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mmse_curve\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_curve\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    111\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    169\u001b[0m                  \u001b[0mmaximize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'maximize'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m                  \u001b[0mforeach\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'foreach'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m                  capturable=group['capturable'])\n\u001b[0m\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    224\u001b[0m          \u001b[0meps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m          \u001b[0mmaximize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmaximize\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 226\u001b[0;31m          capturable=capturable)\n\u001b[0m\u001b[1;32m    227\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36m_single_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable)\u001b[0m\n\u001b[1;32m    303\u001b[0m                 \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmax_exp_avg_sqs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction2_sqrt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 305\u001b[0;31m                 \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction2_sqrt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m             \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcdiv_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexp_avg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdenom\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mstep_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "loss_curve = []\n",
    "energy_curve = []\n",
    "entropy_curve = []\n",
    "mse_curve = []\n",
    "\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "jac = torch.tensor(True, requires_grad=False)\n",
    "for epoch in range(50):\n",
    "    for id, (x, _) in enumerate(data_loader):\n",
    "        (bs, _, dim, dim) = x.shape\n",
    "        x = x.to('cuda')\n",
    "        optimizer.zero_grad()\n",
    "        output, times, log_det_jac = model(x.to('cuda'), torch.rand(bs).to('cuda'))\n",
    "        output.to('cpu')\n",
    "        times.to('cpu')\n",
    "        log_det_jac.to('cpu')\n",
    "        mse_loss = mse(output, x)\n",
    "        entropy_loss = entropy(log_det_jac)\n",
    "        energy_loss = energy(output)\n",
    "        loss = mse_loss + energy_loss - beta*entropy_loss\n",
    "        print(loss)\n",
    "        loss.backward()\n",
    "        loss_curve.append(loss.cpu().detach().numpy())\n",
    "        entropy_curve.append(entropy_loss.cpu().detach().numpy())\n",
    "        energy_curve.append(energy_loss.cpu().detach().numpy())\n",
    "        mse_curve.append(mse_loss.cpu().detach().numpy())\n",
    "        optimizer.step()\n",
    "        \n",
    "plt.plot(loss_curve)\n",
    "plt.xlabel(\"Training steps\")\n",
    "plt.ylabel(\"Loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 320
    },
    "id": "H8CXuUf-9ABD",
    "outputId": "cec3cf09-9afb-4ac2-8f4a-33a7d6a084a8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: RuntimeWarning: divide by zero encountered in log\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f1250d42cd0>]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(beta*np.array(entropy_curve))\n",
    "plt.plot(np.log(energy_curve))\n",
    "plt.plot(np.log(mse_curve))\n",
    "plt.plot(np.log(loss_curve - min(loss_curve)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B3n9Pg6e4jXD"
   },
   "outputs": [],
   "source": [
    "plt.plot(-beta*np.array(entropy_curve))\n",
    "plt.plot(np.log(energy_curve))\n",
    "plt.plot(np.log(mse_curve))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
